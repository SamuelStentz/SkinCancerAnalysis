{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All required imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/samuelstentz/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/samuelstentz/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/samuelstentz/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/samuelstentz/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/samuelstentz/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/samuelstentz/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/samuelstentz/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/samuelstentz/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/samuelstentz/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/samuelstentz/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/samuelstentz/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/samuelstentz/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "import sklearn\n",
    "import os\n",
    "import pandas as pd\n",
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This loads data into pandas dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    root\n",
    "except:\n",
    "    root = os.getcwd()\n",
    "\n",
    "data_path = os.path.join(root, \"../skin-cancer-mnist-ham10000\")\n",
    "\n",
    "# the associated meta data\n",
    "metadata = pd.read_csv(os.path.join(data_path, \"HAM10000_metadata.csv\"))\n",
    "\n",
    "# the pixels RGB\n",
    "X_pixels = pd.read_csv(os.path.join(data_path, \"hmnist_28_28_RGB.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10015, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0027419</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0025030</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0026769</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0025661</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HAM_0001466</td>\n",
       "      <td>ISIC_0031633</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>75.0</td>\n",
       "      <td>male</td>\n",
       "      <td>ear</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lesion_id      image_id   dx dx_type   age   sex localization\n",
       "0  HAM_0000118  ISIC_0027419  bkl   histo  80.0  male        scalp\n",
       "1  HAM_0000118  ISIC_0025030  bkl   histo  80.0  male        scalp\n",
       "2  HAM_0002730  ISIC_0026769  bkl   histo  80.0  male        scalp\n",
       "3  HAM_0002730  ISIC_0025661  bkl   histo  80.0  male        scalp\n",
       "4  HAM_0001466  ISIC_0031633  bkl   histo  75.0  male          ear"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(metadata.shape)\n",
    "metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10015, 2353)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel0000</th>\n",
       "      <th>pixel0001</th>\n",
       "      <th>pixel0002</th>\n",
       "      <th>pixel0003</th>\n",
       "      <th>pixel0004</th>\n",
       "      <th>pixel0005</th>\n",
       "      <th>pixel0006</th>\n",
       "      <th>pixel0007</th>\n",
       "      <th>pixel0008</th>\n",
       "      <th>pixel0009</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel2342</th>\n",
       "      <th>pixel2343</th>\n",
       "      <th>pixel2344</th>\n",
       "      <th>pixel2345</th>\n",
       "      <th>pixel2346</th>\n",
       "      <th>pixel2347</th>\n",
       "      <th>pixel2348</th>\n",
       "      <th>pixel2349</th>\n",
       "      <th>pixel2350</th>\n",
       "      <th>pixel2351</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>192</td>\n",
       "      <td>153</td>\n",
       "      <td>193</td>\n",
       "      <td>195</td>\n",
       "      <td>155</td>\n",
       "      <td>192</td>\n",
       "      <td>197</td>\n",
       "      <td>154</td>\n",
       "      <td>185</td>\n",
       "      <td>202</td>\n",
       "      <td>...</td>\n",
       "      <td>134</td>\n",
       "      <td>173</td>\n",
       "      <td>124</td>\n",
       "      <td>138</td>\n",
       "      <td>183</td>\n",
       "      <td>147</td>\n",
       "      <td>166</td>\n",
       "      <td>185</td>\n",
       "      <td>154</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25</td>\n",
       "      <td>14</td>\n",
       "      <td>30</td>\n",
       "      <td>68</td>\n",
       "      <td>48</td>\n",
       "      <td>75</td>\n",
       "      <td>123</td>\n",
       "      <td>93</td>\n",
       "      <td>126</td>\n",
       "      <td>158</td>\n",
       "      <td>...</td>\n",
       "      <td>82</td>\n",
       "      <td>60</td>\n",
       "      <td>39</td>\n",
       "      <td>55</td>\n",
       "      <td>25</td>\n",
       "      <td>14</td>\n",
       "      <td>28</td>\n",
       "      <td>25</td>\n",
       "      <td>14</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>192</td>\n",
       "      <td>138</td>\n",
       "      <td>153</td>\n",
       "      <td>200</td>\n",
       "      <td>145</td>\n",
       "      <td>163</td>\n",
       "      <td>201</td>\n",
       "      <td>142</td>\n",
       "      <td>160</td>\n",
       "      <td>206</td>\n",
       "      <td>...</td>\n",
       "      <td>149</td>\n",
       "      <td>167</td>\n",
       "      <td>129</td>\n",
       "      <td>143</td>\n",
       "      <td>159</td>\n",
       "      <td>124</td>\n",
       "      <td>142</td>\n",
       "      <td>136</td>\n",
       "      <td>104</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38</td>\n",
       "      <td>19</td>\n",
       "      <td>30</td>\n",
       "      <td>95</td>\n",
       "      <td>59</td>\n",
       "      <td>72</td>\n",
       "      <td>143</td>\n",
       "      <td>103</td>\n",
       "      <td>119</td>\n",
       "      <td>171</td>\n",
       "      <td>...</td>\n",
       "      <td>73</td>\n",
       "      <td>44</td>\n",
       "      <td>26</td>\n",
       "      <td>36</td>\n",
       "      <td>25</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "      <td>25</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>158</td>\n",
       "      <td>113</td>\n",
       "      <td>139</td>\n",
       "      <td>194</td>\n",
       "      <td>144</td>\n",
       "      <td>174</td>\n",
       "      <td>215</td>\n",
       "      <td>162</td>\n",
       "      <td>191</td>\n",
       "      <td>225</td>\n",
       "      <td>...</td>\n",
       "      <td>201</td>\n",
       "      <td>209</td>\n",
       "      <td>166</td>\n",
       "      <td>185</td>\n",
       "      <td>172</td>\n",
       "      <td>135</td>\n",
       "      <td>149</td>\n",
       "      <td>109</td>\n",
       "      <td>78</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2352 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pixel0000  pixel0001  pixel0002  pixel0003  pixel0004  pixel0005  \\\n",
       "0        192        153        193        195        155        192   \n",
       "1         25         14         30         68         48         75   \n",
       "2        192        138        153        200        145        163   \n",
       "3         38         19         30         95         59         72   \n",
       "4        158        113        139        194        144        174   \n",
       "\n",
       "   pixel0006  pixel0007  pixel0008  pixel0009  ...  pixel2342  pixel2343  \\\n",
       "0        197        154        185        202  ...        134        173   \n",
       "1        123         93        126        158  ...         82         60   \n",
       "2        201        142        160        206  ...        149        167   \n",
       "3        143        103        119        171  ...         73         44   \n",
       "4        215        162        191        225  ...        201        209   \n",
       "\n",
       "   pixel2344  pixel2345  pixel2346  pixel2347  pixel2348  pixel2349  \\\n",
       "0        124        138        183        147        166        185   \n",
       "1         39         55         25         14         28         25   \n",
       "2        129        143        159        124        142        136   \n",
       "3         26         36         25         12         17         25   \n",
       "4        166        185        172        135        149        109   \n",
       "\n",
       "   pixel2350  pixel2351  \n",
       "0        154        177  \n",
       "1         14         27  \n",
       "2        104        117  \n",
       "3         12         15  \n",
       "4         78         92  \n",
       "\n",
       "[5 rows x 2352 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X_pixels.shape)\n",
    "X_pixels.drop(['label'], axis=1,inplace = True)\n",
    "X_pixels.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reformat metadata into X_metadata, categorical variables turned into one hot encoding, non-features removed.\n",
    "Also make variable y into the classifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>dx_type_confocal</th>\n",
       "      <th>dx_type_consensus</th>\n",
       "      <th>dx_type_follow_up</th>\n",
       "      <th>dx_type_histo</th>\n",
       "      <th>sex_female</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>sex_unknown</th>\n",
       "      <th>localization_abdomen</th>\n",
       "      <th>localization_acral</th>\n",
       "      <th>...</th>\n",
       "      <th>localization_face</th>\n",
       "      <th>localization_foot</th>\n",
       "      <th>localization_genital</th>\n",
       "      <th>localization_hand</th>\n",
       "      <th>localization_lower extremity</th>\n",
       "      <th>localization_neck</th>\n",
       "      <th>localization_scalp</th>\n",
       "      <th>localization_trunk</th>\n",
       "      <th>localization_unknown</th>\n",
       "      <th>localization_upper extremity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>75.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  dx_type_confocal  dx_type_consensus  dx_type_follow_up  \\\n",
       "0  80.0                 0                  0                  0   \n",
       "1  80.0                 0                  0                  0   \n",
       "2  80.0                 0                  0                  0   \n",
       "3  80.0                 0                  0                  0   \n",
       "4  75.0                 0                  0                  0   \n",
       "\n",
       "   dx_type_histo  sex_female  sex_male  sex_unknown  localization_abdomen  \\\n",
       "0              1           0         1            0                     0   \n",
       "1              1           0         1            0                     0   \n",
       "2              1           0         1            0                     0   \n",
       "3              1           0         1            0                     0   \n",
       "4              1           0         1            0                     0   \n",
       "\n",
       "   localization_acral  ...  localization_face  localization_foot  \\\n",
       "0                   0  ...                  0                  0   \n",
       "1                   0  ...                  0                  0   \n",
       "2                   0  ...                  0                  0   \n",
       "3                   0  ...                  0                  0   \n",
       "4                   0  ...                  0                  0   \n",
       "\n",
       "   localization_genital  localization_hand  localization_lower extremity  \\\n",
       "0                     0                  0                             0   \n",
       "1                     0                  0                             0   \n",
       "2                     0                  0                             0   \n",
       "3                     0                  0                             0   \n",
       "4                     0                  0                             0   \n",
       "\n",
       "   localization_neck  localization_scalp  localization_trunk  \\\n",
       "0                  0                   1                   0   \n",
       "1                  0                   1                   0   \n",
       "2                  0                   1                   0   \n",
       "3                  0                   1                   0   \n",
       "4                  0                   0                   0   \n",
       "\n",
       "   localization_unknown  localization_upper extremity  \n",
       "0                     0                             0  \n",
       "1                     0                             0  \n",
       "2                     0                             0  \n",
       "3                     0                             0  \n",
       "4                     0                             0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_metadata = metadata.loc[:, ['dx_type', 'age', 'sex', 'localization']]\n",
    "X_metadata = pd.get_dummies(data=X_metadata, columns=['dx_type', 'sex', 'localization'])\n",
    "X_metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>akiec</th>\n",
       "      <th>bcc</th>\n",
       "      <th>bkl</th>\n",
       "      <th>df</th>\n",
       "      <th>mel</th>\n",
       "      <th>nv</th>\n",
       "      <th>vasc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   akiec  bcc  bkl  df  mel  nv  vasc\n",
       "0      0    0    1   0    0   0     0\n",
       "1      0    0    1   0    0   0     0\n",
       "2      0    0    1   0    0   0     0\n",
       "3      0    0    1   0    0   0     0\n",
       "4      0    0    1   0    0   0     0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = metadata.loc[:, 'dx']\n",
    "y = pd.get_dummies(data=y, columns=['dx'])\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simply make X be the concatenation of X_pixels and X_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>dx_type_confocal</th>\n",
       "      <th>dx_type_consensus</th>\n",
       "      <th>dx_type_follow_up</th>\n",
       "      <th>dx_type_histo</th>\n",
       "      <th>sex_female</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>sex_unknown</th>\n",
       "      <th>localization_abdomen</th>\n",
       "      <th>localization_acral</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel2342</th>\n",
       "      <th>pixel2343</th>\n",
       "      <th>pixel2344</th>\n",
       "      <th>pixel2345</th>\n",
       "      <th>pixel2346</th>\n",
       "      <th>pixel2347</th>\n",
       "      <th>pixel2348</th>\n",
       "      <th>pixel2349</th>\n",
       "      <th>pixel2350</th>\n",
       "      <th>pixel2351</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>134</td>\n",
       "      <td>173</td>\n",
       "      <td>124</td>\n",
       "      <td>138</td>\n",
       "      <td>183</td>\n",
       "      <td>147</td>\n",
       "      <td>166</td>\n",
       "      <td>185</td>\n",
       "      <td>154</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>82</td>\n",
       "      <td>60</td>\n",
       "      <td>39</td>\n",
       "      <td>55</td>\n",
       "      <td>25</td>\n",
       "      <td>14</td>\n",
       "      <td>28</td>\n",
       "      <td>25</td>\n",
       "      <td>14</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>149</td>\n",
       "      <td>167</td>\n",
       "      <td>129</td>\n",
       "      <td>143</td>\n",
       "      <td>159</td>\n",
       "      <td>124</td>\n",
       "      <td>142</td>\n",
       "      <td>136</td>\n",
       "      <td>104</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>73</td>\n",
       "      <td>44</td>\n",
       "      <td>26</td>\n",
       "      <td>36</td>\n",
       "      <td>25</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "      <td>25</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>75.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>201</td>\n",
       "      <td>209</td>\n",
       "      <td>166</td>\n",
       "      <td>185</td>\n",
       "      <td>172</td>\n",
       "      <td>135</td>\n",
       "      <td>149</td>\n",
       "      <td>109</td>\n",
       "      <td>78</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2375 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  dx_type_confocal  dx_type_consensus  dx_type_follow_up  \\\n",
       "0  80.0                 0                  0                  0   \n",
       "1  80.0                 0                  0                  0   \n",
       "2  80.0                 0                  0                  0   \n",
       "3  80.0                 0                  0                  0   \n",
       "4  75.0                 0                  0                  0   \n",
       "\n",
       "   dx_type_histo  sex_female  sex_male  sex_unknown  localization_abdomen  \\\n",
       "0              1           0         1            0                     0   \n",
       "1              1           0         1            0                     0   \n",
       "2              1           0         1            0                     0   \n",
       "3              1           0         1            0                     0   \n",
       "4              1           0         1            0                     0   \n",
       "\n",
       "   localization_acral  ...  pixel2342  pixel2343  pixel2344  pixel2345  \\\n",
       "0                   0  ...        134        173        124        138   \n",
       "1                   0  ...         82         60         39         55   \n",
       "2                   0  ...        149        167        129        143   \n",
       "3                   0  ...         73         44         26         36   \n",
       "4                   0  ...        201        209        166        185   \n",
       "\n",
       "   pixel2346  pixel2347  pixel2348  pixel2349  pixel2350  pixel2351  \n",
       "0        183        147        166        185        154        177  \n",
       "1         25         14         28         25         14         27  \n",
       "2        159        124        142        136        104        117  \n",
       "3         25         12         17         25         12         15  \n",
       "4        172        135        149        109         78         92  \n",
       "\n",
       "[5 rows x 2375 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pd.concat([X_metadata, X_pixels], axis = 1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is going to be all of my analysis using CNN from keras: Samuel Stentz.\n",
    "\n",
    "I am also going to be using some slight data augmentation to help make the classifier more robust\n",
    "\n",
    "https://medium.com/datadriveninvestor/keras-imagedatagenerator-methods-an-easy-guide-550ecd3c0a92\n",
    "\n",
    "This is the article some of this code is from which we should cite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move all images to one directory\n",
    "import shutil\n",
    "im1 = os.path.join(data_path, \"HAM10000_images_part_1\")\n",
    "im2 = os.path.join(data_path, \"HAM10000_images_part_2\")\n",
    "\n",
    "i = 0\n",
    "for im in os.listdir(im2):\n",
    "    i += 1\n",
    "    print(f\"im {i} moved\")\n",
    "    shutil.move(os.path.join(im2,im), im1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = metadata.loc[:,[\"dx\", \"image_id\"]]\n",
    "dataset.columns = [\"label\", \"filename\"]\n",
    "\n",
    "def to_jpg(x):\n",
    "    return f\"{x}.jpg\"\n",
    "\n",
    "dataset['filename'] = dataset['filename'].apply(lambda x: f\"{x}.jpg\")\n",
    "dataset.head()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_dataset, test_dataset = train_test_split(dataset, test_size=0.2, random_state = 42)\n",
    "train_dataset, val_dataset = train_test_split(train_dataset, test_size=0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/samuelstentz/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "Found 6409 validated image filenames belonging to 7 classes.\n",
      "Found 1603 validated image filenames belonging to 7 classes.\n",
      "Found 2003 validated image filenames belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# where all the data comes from\n",
    "train_data_dir = im1\n",
    "\n",
    "# dimensions of our images.\n",
    "img_width, img_height = 150, 150\n",
    "\n",
    "nb_train_samples = 6409\n",
    "nb_validation_samples = 1603\n",
    "nb_test_samples = 2003\n",
    "epochs = 50\n",
    "batch_size = 32\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, img_width, img_height)\n",
    "else:\n",
    "    input_shape = (img_width, img_height, 3)\n",
    "\n",
    "#############################################################################################################\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(7))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "##############################################################################################################\n",
    "\"\"\"shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.2) # set validation split\"\"\"\n",
    "\n",
    "# this is the augmentation configuration we will use for training (Nothing!!!)\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255\n",
    ")\n",
    "test_datagen = ImageDataGenerator(\n",
    "    rescale=1./255\n",
    ")\n",
    "\n",
    "# all the generators for train, val, and test\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    dataframe = train_dataset,\n",
    "    directory = train_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    x_col = \"filename\",\n",
    "    y_col = \"label\",\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_generator = train_datagen.flow_from_dataframe(\n",
    "    dataframe = val_dataset,\n",
    "    directory = train_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    x_col = \"filename\",\n",
    "    y_col = \"label\",\n",
    "    class_mode='categorical')\n",
    "\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "    dataframe = test_dataset,\n",
    "    directory = train_data_dir,\n",
    "    target_size= (img_height, img_width),\n",
    "    batch_size= batch_size,\n",
    "    x_col = \"filename\",\n",
    "    y_col = \"label\",\n",
    "    class_mode='categorical',\n",
    "    shuffle = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the training of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model with best validation accuracy\n",
    "mcp = ModelCheckpoint(\"best_validation.hdf5\", monitor=\"val_accuracy\", save_best_only=True, save_weights_only=False)\n",
    "\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=nb_train_samples // batch_size + 1,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=nb_validation_samples // batch_size + 1,\n",
    "    callbacks=[mcp])\n",
    "\n",
    "model.save_weights('first_try.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/samuelstentz/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# load model and evaluate on test set\n",
    "from keras.models import load_model\n",
    "\n",
    "model.load_weights('best_validation.hdf5')\n",
    "\n",
    "test_generator.reset()\n",
    "y_pred = model.predict_generator(test_generator,steps= nb_test_samples // batch_size + 1)\n",
    "y_pred = np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = test_generator.class_indices\n",
    "reverse = dict()\n",
    "for l in label_map:\n",
    "    reverse[label_map[l]] = l\n",
    "\n",
    "names = []\n",
    "for number in reverse:\n",
    "    names.append(reverse[number])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "labels = test_generator.classes\n",
    "\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(labels, y_pred))\n",
    "print('\\n\\n\\nClassification Report')\n",
    "print(classification_report(labels, y_pred, target_names=names))\n",
    "num_right = np.sum(labels == y_pred)\n",
    "print(f\"\\nAccuracy {num_right / y_pred.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import math\n",
    "\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "import matplotlib as mpl\n",
    "\n",
    "mpl.style.use('seaborn')\n",
    "\n",
    "conf_arr = confusion_matrix(labels, y_pred)\n",
    "\n",
    "s = conf_arr.sum(axis = 1)\n",
    "\n",
    "conf_arr = (conf_arr * 100.0) / s[:,None]\n",
    "\n",
    "conf_arr = np.nan_to_num(conf_arr)\n",
    "\n",
    "df_cm = pd.DataFrame(conf_arr, \n",
    "  index = names,\n",
    "  columns = names)\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "plt.clf()\n",
    "\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set_aspect(1)\n",
    "\n",
    "cmap = sns.cubehelix_palette(light=1, as_cmap=True)\n",
    "\n",
    "res = sn.heatmap(df_cm, annot=True, vmin=0.0, vmax=100.0, fmt='.2f', cmap=cmap)\n",
    "\n",
    "res.invert_yaxis()\n",
    "\n",
    "plt.yticks(np.arange(len(names)) + .5, names,va='center')\n",
    "\n",
    "plt.title('Percent Classified')\n",
    "plt.xlabel(\"Prediction\")\n",
    "plt.ylabel(\"Class\")\n",
    "\n",
    "plt.savefig('confusion_matrix_cnn.png', dpi=100, bbox_inches='tight' )\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
